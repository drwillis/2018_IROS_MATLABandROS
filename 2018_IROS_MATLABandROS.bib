% Encoding: UTF-8


@InProceedings{5981571,
  Title                    = {Automatic construction of polygonal maps from point cloud data},
  Author                   = {T. Wiemann and A. Nüchter and K. Lingemann and S. Stiene and J. Hertzberg},
  Booktitle                = {2010 IEEE Safety Security and Rescue Robotics},
  Year                     = {2010},
  Month                    = {July},
  Pages                    = {1-6},
  DOI                      = {10.1109/SSRR.2010.5981571},
  ISSN                     = {2374-3247},
  Keywords                 = {mobile robots;path planning;3D point cloud data;indoor environments;polygonal maps automatic construction;selflocalization}
}

@InProceedings{6233120,
  Title                    = {Planar Segmentation of RGBD Images Using Fast Linear Fitting and Markov Chain Monte Carlo},
  Author                   = {C. Erdogan and M. Paluri and F. Dellaert},
  Booktitle                = {2012 Ninth Conference on Computer and Robot Vision},
  Year                     = {2012},
  Month                    = {May},
  Pages                    = {32-39},
  Abstract                 = {With the advent of affordable RGBD sensors such as the Kinect, the collection of depth and appearance information from a scene has become effortless. However, neither the correct noise model for these sensors, nor a principled methodology for extracting planar segmentations has been developed yet. In this work, we advance the state of art with the following contributions: we correctly model the Kinect sensor data by observing that the data has inherent noise only over the measured disparity values, we formulate plane fitting as a linear least-squares problem that allow us to quickly merge different segments, and we apply an advanced Markov Chain Monte Carlo (MCMC) method, generalized Swendsen-Wang sampling, to efficiently search the space of planar segmentations. We evaluate our plane fitting and surface reconstruction algorithms with simulated and real-world data.},
  DOI                      = {10.1109/CRV.2012.12},
  Keywords                 = {Markov processes;Monte Carlo methods;image reconstruction;image segmentation;image sensors;least squares approximations;Kinect sensor data;Markov chain Monte Carlo method;RGBD images;RGBD sensors;Swendsen-Wang sampling;advanced MCMC method;disparity values;fast linear fitting;linear least-squares problem;planar segmentation;plane fitting;surface reconstruction algorithms;Cameras;Image color analysis;Image reconstruction;Image segmentation;Noise;Sensors;Surface reconstruction;Generalized Swendsen-Wang Sampling;Linear Plane Fitting;Planar Segmentation;Surface Reconstruction}
}

@InProceedings{6385773,
  Title                    = {A benchmark for the evaluation of RGB-D SLAM systems},
  Author                   = {J. Sturm and N. Engelhard and F. Endres and W. Burgard and D. Cremers},
  Booktitle                = {2012 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  Year                     = {2012},
  Month                    = {Oct},
  Pages                    = {573-580},
  Abstract                 = {In this paper, we present a novel benchmark for the evaluation of RGB-D SLAM systems. We recorded a large set of image sequences from a Microsoft Kinect with highly accurate and time-synchronized ground truth camera poses from a motion capture system. The sequences contain both the color and depth images in full sensor resolution (640 × 480) at video frame rate (30 Hz). The ground-truth trajectory was obtained from a motion-capture system with eight high-speed tracking cameras (100 Hz). The dataset consists of 39 sequences that were recorded in an office environment and an industrial hall. The dataset covers a large variety of scenes and camera motions. We provide sequences for debugging with slow motions as well as longer trajectories with and without loop closures. Most sequences were recorded from a handheld Kinect with unconstrained 6-DOF motions but we also provide sequences from a Kinect mounted on a Pioneer 3 robot that was manually navigated through a cluttered indoor environment. To stimulate the comparison of different approaches, we provide automatic evaluation tools both for the evaluation of drift of visual odometry systems and the global pose error of SLAM systems. The benchmark website [1] contains all data, detailed descriptions of the scenes, specifications of the data formats, sample code, and evaluation tools.},
  DOI                      = {10.1109/IROS.2012.6385773},
  ISSN                     = {2153-0858},
  Keywords                 = {SLAM (robots);cameras;distance measurement;image colour analysis;image resolution;image sequences;object tracking;pose estimation;Microsoft Kinect;Pioneer 3 robot;RGB-D SLAM systems;automatic evaluation tools;camera motions;cluttered indoor environment;color image;depth image;full sensor resolution;global pose error;ground truth camera poses;ground-truth trajectory;handheld Kinect;high-speed tracking cameras;image sequences;industrial hall;loop closures;motion capture system;motion-capture system;office environment;slow motions;unconstrained 6DOF motions;video frame rate;visual odometry systems;Calibration;Cameras;Simultaneous localization and mapping;Trajectory;Visualization}
}

@Article{6547194,
  Title                    = {Enhanced Computer Vision With Microsoft Kinect Sensor: A Review},
  Author                   = {J. Han and L. Shao and D. Xu and J. Shotton},
  Journal                  = {IEEE Transactions on Cybernetics},
  Year                     = {2013},
  Month                    = {Oct},
  Number                   = {5},
  Pages                    = {1318-1334},
  Volume                   = {43},
  Abstract                 = {With the invention of the low-cost Microsoft Kinect sensor, high-resolution depth and visual (RGB) sensing has become available for widespread use. The complementary nature of the depth and visual information provided by the Kinect sensor opens up new opportunities to solve fundamental problems in computer vision. This paper presents a comprehensive review of recent Kinect-based computer vision algorithms and applications. The reviewed approaches are classified according to the type of vision problems that can be addressed or enhanced by means of the Kinect sensor. The covered topics include preprocessing, object tracking and recognition, human activity analysis, hand gesture analysis, and indoor 3-D mapping. For each category of methods, we outline their main algorithmic contributions and summarize their advantages/differences compared to their RGB counterparts. Finally, we give an overview of the challenges in this field and future research trends. This paper is expected to serve as a tutorial and source of references for Kinect-based computer vision researchers.},
  DOI                      = {10.1109/TCYB.2013.2265378},
  ISSN                     = {2168-2267},
  Keywords                 = {computer vision;gesture recognition;image sensors;object recognition;object tracking;Kinect-based computer vision algorithm;Microsoft Kinect sensor;RGB sensing;hand gesture analysis;human activity analysis;indoor 3D mapping;object recognition;object tracking;Algorithm design and analysis;Cameras;Computer vision;Data integration;Feature extraction;Object recognition;Sensors;Computer vision;Kinect sensor;depth image;information fusion;Actigraphy;Algorithms;Artificial Intelligence;Computer Peripherals;Computer Simulation;Image Enhancement;Imaging, Three-Dimensional;Pattern Recognition, Automated;Transducers;Video Games;Whole Body Imaging}
}

@InProceedings{990517,
  Title                    = {Rapid object detection using a boosted cascade of simple features},
  Author                   = {P. Viola and M. Jones},
  Booktitle                = {Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001},
  Year                     = {2001},
  Pages                    = {I-511-I-518 vol.1},
  Volume                   = {1},
  Abstract                 = {This paper describes a machine learning approach for visual object detection which is capable of processing images extremely rapidly and achieving high detection rates. This work is distinguished by three key contributions. The first is the introduction of a new image representation called the "integral image" which allows the features used by our detector to be computed very quickly. The second is a learning algorithm, based on AdaBoost, which selects a small number of critical visual features from a larger set and yields extremely efficient classifiers. The third contribution is a method for combining increasingly more complex classifiers in a "cascade" which allows background regions of the image to be quickly discarded while spending more computation on promising object-like regions. The cascade can be viewed as an object specific focus-of-attention mechanism which unlike previous approaches provides statistical guarantees that discarded regions are unlikely to contain the object of interest. In the domain of face detection the system yields detection rates comparable to the best previous systems. Used in real-time applications, the detector runs at 15 frames per second without resorting to image differencing or skin color detection.},
  DOI                      = {10.1109/CVPR.2001.990517},
  ISSN                     = {1063-6919},
  Keywords                 = {feature extraction;image classification;image representation;learning (artificial intelligence);object detection;AdaBoost;background regions;boosted simple feature cascade;classifiers;face detection;image processing;image representation;integral image;machine learning;object specific focus-of-attention mechanism;rapid object detection;real-time applications;statistical guarantees;visual object detection;Detectors;Face detection;Filters;Focusing;Image representation;Machine learning;Object detection;Pixel;Robustness;Skin}
}

@InProceedings{Henry10rgb-dmapping:,
  Title                    = {RGB-D Mapping: Using depth cameras for dense 3D modeling of indoor environments},
  Author                   = {Peter Henry and Michael Krainin and Evan Herbst and Xiaofeng Ren and Dieter Fox},
  Booktitle                = {In the 12th International Symposium on Experimental Robotics (ISER},
  Year                     = {2010}
}

@InProceedings{Holz11real-timeplane,
  Title                    = {Real-time plane segmentation using RGB-D cameras},
  Author                   = {Dirk Holz and Stefan Holzer and Radu Bogdan Rusu and Sven Behnke},
  Booktitle                = {In Proc. of the 15th RoboCup Int. Symp},
  Year                     = {2011}
}

@InProceedings{lewis1995fast,
  Title                    = {Fast template matching},
  Author                   = {Lewis, John P},
  Booktitle                = {Vision interface},
  Year                     = {1995},
  Number                   = {120123},
  Pages                    = {15--19},
  Volume                   = {95}
}

@Article{s120201437,
  Title                    = {Accuracy and Resolution of Kinect Depth Data for Indoor Mapping Applications},
  Author                   = {Khoshelham, Kourosh and Elberink, Sander Oude},
  Journal                  = {Sensors},
  Year                     = {2012},
  Number                   = {2},
  Pages                    = {1437},
  Volume                   = {12},
  DOI                      = {10.3390/s120201437},
  ISSN                     = {1424-8220},
  Pubmedid                 = {22438718},
  URL                      = {http://www.mdpi.com/1424-8220/12/2/1437}
}

@Article{Taubin:Fitting:1991,
  Title                    = {Estimation of planar curves, surfaces and nonplanar space curves defined by implicit equations, with applications to edge and range image segmentation},
  Author                   = {Taubin, Gabriel},
  Journal                  = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  Year                     = {1991},
  Number                   = {11},
  Pages                    = {1115--1138},
  Volume                   = {13}
}

@InProceedings{TitusJiaJieTang2011,
  author    = {Titus Jia Jie Tang and Wen Lik Dennis Lui and Wai Ho Li},
  title     = {A lightweight approach to 6-DOF plane-based egomotion estimation using inverse depth},
  booktitle = {Australasian Conference on Robotics and Automation},
  year      = {2011},
  owner     = {john-papadakis},
  timestamp = {2017.01.06},
}

@Misc{itseez2015opencv,
  author       = {Itseez},
  title        = {Open Source Computer Vision Library},
  howpublished = {\url{https://github.com/itseez/opencv}},
  year         = {2015},
}

@InProceedings{Rusu_ICRA2011_PCL,
  author    = {Radu Bogdan Rusu and Steve Cousins},
  title     = {{3D is here: Point Cloud Library (PCL)}},
  booktitle = {{IEEE International Conference on Robotics and Automation (ICRA)}},
  year      = {2011},
  address   = {Shanghai, China},
  month     = {May 9-13},
}

@Book{Trucco:1998:ITC:551277,
  title     = {Introductory Techniques for 3-D Computer Vision},
  publisher = {Prentice Hall PTR},
  year      = {1998},
  author    = {Trucco, Emanuele and Verri, Alessandro},
  address   = {Upper Saddle River, NJ, USA},
  isbn      = {0132611082},
}

@Article{Fitzgibbon:1999:DLS:302943.302950,
  author     = {Fitzgibbon, Andrew and Pilu, Maurizio and Fisher, Robert B.},
  title      = {Direct Least Square Fitting of Ellipses},
  journal    = {IEEE Trans. Pattern Anal. Mach. Intell.},
  year       = {1999},
  volume     = {21},
  number     = {5},
  pages      = {476--480},
  month      = may,
  issn       = {0162-8828},
  acmid      = {302950},
  address    = {Washington, DC, USA},
  doi        = {10.1109/34.765658},
  issue_date = {May 1999},
  keywords   = {Algebraic models, ellipse fitting, least squares fitting, constrained minimization, generalized eigenvalue problem.},
  numpages   = {5},
  publisher  = {IEEE Computer Society},
  url        = {https://doi.org/10.1109/34.765658},
}

@Article{4059046,
  pages    = {4066-4071},
  keywords = {SLAM (robots);genetic algorithms;mobile robots;evolutionary SLAM algorithm;island model genetic algorithm;loop closing problem;mobile robots;simultaneous localization and mapping;Current measurement;Feature extraction;Genetic algorithms;Indoor environments;Intelligent robots;Mobile robots;Particle filters;Particle measurements;Robot sensing systems;Simultaneous localization and mapping},
}

@InProceedings{4059046,
  author    = {M. Begum and G. K. I. Mann and R. G. Gosine},
  title     = {An Evolutionary SLAM Algorithm for Mobile Robots},
  booktitle = {2006 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  year      = {2006},
  pages     = {4066-4071},
  month     = {Oct},
  doi       = {10.1109/IROS.2006.281870},
  issn      = {2153-0858},
  keywords  = {SLAM (robots);genetic algorithms;mobile robots;evolutionary SLAM algorithm;island model genetic algorithm;loop closing problem;mobile robots;simultaneous localization and mapping;Current measurement;Feature extraction;Genetic algorithms;Indoor environments;Intelligent robots;Mobile robots;Particle filters;Particle measurements;Robot sensing systems;Simultaneous localization and mapping},
}

@Comment{jabref-meta: databaseType:bibtex;}
